{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import scipy.stats\n",
    "import scipy\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [0.123,0.123,0.231,0.2321,0.2324,23432]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(arr_full,step, size):\n",
    "    step = step\n",
    "    size = size\n",
    "    segmented = []\n",
    "    i = 0\n",
    "    while i < len(arr_full):\n",
    "        segment = arr_full[i : i + size]\n",
    "        segmented.append(segment)\n",
    "        i += step\n",
    "    return segmented "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Features(object):\n",
    "    def __init__(self,arr):\n",
    "        self.arr = np.array(arr)\n",
    "        self.var = np.var(self.arr)\n",
    "        self.mean = np.mean(self.arr)\n",
    "        self.rms = np.sqrt(np.mean(np.square(self.arr)))\n",
    "        self.energy = np.mean(np.square(self.arr))\n",
    "        #self.mcr = self.mean_crossing_rate()\n",
    "        self.aad = np.mean(np.abs(self.arr))\n",
    "        self.kurtosis_val = scipy.stats.kurtosis(self.arr)\n",
    "        #self.zero_crossing_rate = self.zero_crossing_rate_func()\n",
    "        self.skew = scipy.stats.skew(self.arr)\n",
    "\n",
    "    def get_features(self):\n",
    "        return(self.var,\n",
    "        self.mean,\n",
    "        self.rms,\n",
    "        self.energy,\n",
    "        self.aad ,\n",
    "        self.kurtosis_val,\n",
    "        self.skew)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = Features(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feat.get_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76256916.60573815,\n",
       " 3905.4902500000003,\n",
       " 9566.073943817451,\n",
       " 91509770.69858319,\n",
       " 3905.4902500000003,\n",
       " 1.1999999997763116,\n",
       " 1.7888543818747866)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_scale(valence, arousal, num_classes = 2):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    valence score array: from 1-5 where 1 = negative, 5 = positive, 3 = origin,\n",
    "    arousal score array: from 1-5 where 1 = low , 5 = high , 3 = neutral/origin.\n",
    "    output:\n",
    "    class: 1 or 0 depending whether classification score landed in the right quadrant\n",
    "    \"\"\"\n",
    "\n",
    "    class_list = []\n",
    "    arousal = -1 * arousal \n",
    "    arousal = arousal + 3\n",
    "    valence = valence + 3\n",
    "    if num_classes == 2:\n",
    "        for i in range(len(valence)):\n",
    "            if valence[i] < 3:\n",
    "                if arousal[i] > 3:\n",
    "                    class_val = 1\n",
    "                else: \n",
    "                    class_val = 0\n",
    "            else:\n",
    "                class_val = 0\n",
    "            class_list.append(class_val)\n",
    "        assert len(class_list) == len(valence)\n",
    "    else:\n",
    "        for i in range(len(valence)):\n",
    "            if valence[i] < 3:\n",
    "                    if arousal[i] >= 3:\n",
    "                        class_val = 1\n",
    "                    else: \n",
    "                        class_val = 0\n",
    "            else:\n",
    "                class_val = 0\n",
    "            class_list.append(class_val)\n",
    "        for i in range(len(valence)):\n",
    "            if valence[i] >= 3:\n",
    "                if arousal[i] >= 3:\n",
    "                    class_val = 2\n",
    "                    class_list[i] = class_val\n",
    "        for i in range(len(valence)):\n",
    "            if valence[i] >= 3:\n",
    "                if arousal[i] < 3:\n",
    "                    class_val = 3\n",
    "                    class_list[i] = class_val\n",
    "        for i in range(len(valence)):\n",
    "            if valence[i] < 3:\n",
    "                if arousal[i] < 3:\n",
    "                    class_val = 4\n",
    "                    class_list[i] = class_val\n",
    "               \n",
    "    return class_list\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_feat(arr_long,segment = 0):\n",
    "    if segment != 0:\n",
    "        segmented = sliding_window(arr_long,step = 1,size = segment)\n",
    "        all_feat = []\n",
    "        for seg in segmented:\n",
    "            feat = Features(seg)\n",
    "            features = feat.get_features()\n",
    "            all_feat.append(np.array(features))\n",
    "        all_feat = np.array(all_feat)\n",
    "        return all_feat\n",
    "    else:\n",
    "        feat = Features(arr_long)\n",
    "        features = feat.get_features()\n",
    "        return features\n",
    "\n",
    "\n",
    "val_dict_ext = {\n",
    "  \"run1_clip1\": {\n",
    "    \"arousel\": -1,\n",
    "    \"heartrate\": [141, 141, 132, 125, 120, 104, 91, 82, 75],\n",
    "    \"gsr\": [824, 827, 824, 824, 824, 825, 825, 824, 826],\n",
    "    \"valence\": 1\n",
    "    },\n",
    "  \"run1_clip2\": {\n",
    "    \"arousel\": -2,\n",
    "    \"valence\": 2,\n",
    "    \"heartrate\": [70, 79, 86, 91, 95, 98, 100],\n",
    "    \"gsr\": [827, 824, 824, 825, 824, 824, 824]\n",
    "  }\n",
    "}\n",
    "\n",
    "def read_data(json_file,window_size = 0 ):\n",
    "    heart_rate = []\n",
    "    gsr = []\n",
    "    valence_list = []\n",
    "    arousal_list = []\n",
    "    with open(json_file) as file:  \n",
    "        json_dict = json.load(file)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    if window_size == 0:\n",
    "        for clip, values in json_dict.items():\n",
    "            arousal = values['arousel'] \n",
    "            valence = values['valence']\n",
    "            valence_list.append(valence)\n",
    "            arousal_list.append(arousal)\n",
    "            heart_rate_feat = gather_feat(np.array(values['heartrate']))\n",
    "            gsr_feat = gather_feat(np.array(values['gsr']))\n",
    "            heart_rate.append(heart_rate_feat)\n",
    "            gsr.append(gsr_feat)\n",
    "    else: \n",
    "        for clip, values in json_dict.items():\n",
    "\n",
    "            arousal = values['arousel'] \n",
    "            valence = values['valence']\n",
    "            heart_rate_feat = gather_feat(np.array(values['heartrate']),segment = window_size)\n",
    "            gsr_feat = gather_feat(np.array(values['gsr']), segment = window_size)\n",
    "            valence = np.repeat(valence, gsr_feat.shape[0])\n",
    "            arousal = np.repeat(arousal, gsr_feat.shape[0])\n",
    "            valence_list.extend(valence)\n",
    "            arousal_list.extend(arousal)\n",
    "            heart_rate.extend(heart_rate_feat)\n",
    "            gsr.extend(gsr_feat)\n",
    "    return np.array(heart_rate),np.array(gsr), np.array(valence_list), np.array(arousal_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2726, 7)\n"
     ]
    }
   ],
   "source": [
    "datapath = '/Users/Amelie/Downloads/data_collection'\n",
    "json_files = glob.glob(datapath + '/*')\n",
    "hr_all, gsr_all, val_all, aro_all = read_data(json_files[0], window_size = 1) \n",
    "\n",
    "for json_file in json_files:\n",
    "    hr, gsr, val, aro = read_data(json_file, window_size = 0)\n",
    "    hr_all = np.append(hr_all,hr,axis = 0)\n",
    "    gsr_all = np.append(gsr_all,gsr,axis = 0)\n",
    "    val_all = np.append(val_all,val, axis = 0)\n",
    "    aro_all = np.append(aro_all,aro, axis = 0)\n",
    "                       \n",
    "\n",
    "print(hr_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def svm_classifier(input_feat,labels):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    input_feat: n_samples x n_features\n",
    "    labels: n_samples (0,1)\n",
    "    output:\n",
    "    \"\"\"\n",
    "    X = input_feat\n",
    "    Y = labels \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state = 100000)\n",
    "    #tuned_parameters = [{'C': np.logspace(-6,3, num = 9,base = 10), 'kernel': ['linear', 'rbf'], \n",
    "    #                      'gamma' : np.logspace(-6,3,num=9,base = 10)}]\n",
    "    #clf = GridSearchCV(svm.SVC(), tuned_parameters, cv=9)\n",
    "    #clf.fit(X_train, Y_train)\n",
    "    #C = clf.best_params_[\"C\"]\n",
    "    #kernel = clf.best_params_['kernel']\n",
    "    #gamma = clf.best_params_['gamma']\n",
    "    #clf  = svm.SVC(kernel=kernel,C = C, gamma = gamma)\n",
    "    #clf  = svm.SVC(kernel='rbf',C = 1000, gamma = 'auto', class_weight  ={1: 20})\n",
    "    #clf  = svm.SVC(kernel='rbf',C = 1000, gamma = 'auto', class_weight  ={1: 4})\n",
    "    clf  = svm.SVC(kernel='rbf',C = 0.3, gamma = 'auto', class_weight  ={1: 4})\n",
    "    x = clf.fit(X_train,Y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    \n",
    "    return pred, Y_test,clf,X_test\n",
    "def decision_tres(input_feat,labels):\n",
    "\n",
    "    pass\n",
    "\n",
    "def logistic(input_feat,labels):\n",
    "    X = input_feat\n",
    "    Y = labels \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state = 100000)\n",
    "    clf = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=100,  class_weight={1 :4}, solver='lbfgs',max_iter = 500)\n",
    "    x = clf.fit(X_train,Y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    accuracy = len(np.intersect1d(np.where(np.array(pred) == 1),np.where(np.array(Y_test) == 1)))/len(np.where(np.array(Y_test)==1)[0])\n",
    "    accuracy2 = len(np.intersect1d(np.where(np.array(pred) == 0),np.where(np.array(Y_test) == 0)))/len(np.where(np.array(Y_test)==0)[0])\n",
    "    #accuracy = np.sum(pred == Y_test)/np.asarray(len(Y), dtype = np.float32)\n",
    "\n",
    "    return pred, accuracy,accuracy2, Y_test,clf,X_test\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96050776 0.73394495]\n",
      "[0.95915493 0.74074074]\n"
     ]
    }
   ],
   "source": [
    "labels = convert_scale(val_all,aro_all, num_classes = 2)\n",
    "pred,true,clf,x_test= svm_classifier(gsr_all,labels)\n",
    "pred1,true1,clf1,x_test1= svm_classifier(hr_all,labels)\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "print(precision_score(true, pred, average = None))\n",
    "print(recall_score(true,pred,average = None))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import coremltools\n",
    "\n",
    "\n",
    "coreml_model = coremltools.converters.sklearn.convert(clf, ['GSR_feat1','GSR_feat2','GSR_feat3','GSR_feat4','GSR_feat5','GSR_feat6','GSR_feat7'], 'emotion class')\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_model.save('anxiety.mlmodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for json_file in json_files:\n",
    "    hr, gsr, val, aro = read_data(json_file, window_size = 10)\n",
    "    hr_all = np.append(hr_all,hr,axis = 0)\n",
    "    gsr_all = np.append(gsr_all,gsr,axis = 0)\n",
    "    val_all = np.append(val_all,val, axis = 0)\n",
    "    aro_all = np.append(aro_all,aro, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
